---
title: Evaluation info
date: 2017-01-05
categories: [Examples]
weight: 3
type: docs  
---
<style>
.full-width-image {
            width: 80%;
            height: auto; /* Maintains the aspect ratio */
        }
</style>

The evaluation for TalentCLEF-2025 will be conducted on **Codabench**. Submissions will be ranked using Mean Average Precision (MAP).

<img src="https://miro.medium.com/v2/resize:fit:1400/1*cIZRfXOzzSobTkTV4i6gVA.png" alt="Codabench" class="full-width-image">


### Evaluation dates 

- **Start Date**: 21st April 2025
- **End Date**: 5th May 2025

Both Task A and Task B will be evaluated during this period.

### Evaluation Criteria

The top-performing teams will be determined based on the following evaluation criteria:

1. **Task A**:
    - **Best Overall Multilingual Performance** – The highest-performing system across English, Spanish, and German, measured as the average Mean Average Precision (MAP) in en-en, es-es, and de-de.
    - **Best Cross-Lingual Performance** – The best-performing system in cross-lingual scenarios, calculated as the average MAP in en-es and en-de.
    - **Best Bias-Controlled Model** – The system that minimizes performance differences across job titles in different gender groups.

    Additionally, there will be a special mention for the best-performing model in Chinese. During the CLEF workshop, certificates will be awarded to the first and second-best systems in each category.

2. **Task B**:  The highest-performing system based on MAP.

